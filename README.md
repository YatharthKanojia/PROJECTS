"train_model.py"
This script is responsible for training machine learning models. It includes data preprocessing, feature engineering, and model training using various algorithms. The script ensures proper data splitting into training and validation sets, and applies cross-validation techniques to optimize model performance. It also saves the trained models to disk for future use.

"create_models.py"
This script focuses on creating and configuring different machine learning models. It includes defining model architectures, setting hyperparameters, and compiling the models. The script may support a variety of algorithms such as linear regression, decision trees, and neural networks. It ensures that each model is prepared and ready for training and evaluation.

"api.py"
This script implements a RESTful API for serving the machine learning models. It handles incoming HTTP requests, processes input data, and returns predictions generated by the trained models. The script uses a framework like Flask or FastAPI to manage the API endpoints, ensuring robust and efficient communication between the client and server. It includes error handling and logging to maintain reliability.

"streamlit_app1.py"
This script creates a web application using Streamlit to provide an interactive user interface for the machine learning models. It allows users to upload data, select models, and view predictions in real-time. The script includes components like file uploaders, dropdown menus, and visualization tools to enhance the user experience. It aims to make model interaction accessible to non-technical users.

"charts.py"
This script trains a sentiment analysis model using a dataset of reviews. It follows a comprehensive process including data loading, preprocessing, model training, evaluation, and result visualization. Initially, the dataset is loaded and cleaned, with reviews being converted to lowercase and non-alphabet characters removed. Sentiment labels are defined based on review scores. The dataset is split into training and test sets, and text data is vectorized and scaled. An XGBoost classifier is trained on the processed data. The trained model, along with the vectorizer and scaler, are saved for future use. The script then evaluates the model's performance using accuracy scores, classification reports, and confusion matrices. Visualizations include a heatmap of the confusion matrix, a pie chart of sentiment distribution, bar charts of classification metrics, and a feature importance bar chart. This ensures a thorough understanding of the model's performance and the most significant features contributing to predictions.

"reviews.csv"
This is the dataset for the implementation of this model.
